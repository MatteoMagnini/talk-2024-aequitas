<!DOCTYPE html><html lang="en"><head>
	<meta name="generator" content="Hugo 0.135.0">
    <meta charset="utf-8">
<title>Enforcing Fairness via Constraint Injection with FaUCI</title>
<meta name="description" content="Enforcing Fairness via Constraint Injection with FaUCI">
<meta name="author" content="Matteo Magnini">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/dist/reset.css">
<link rel="stylesheet" href="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/dist/reveal.css">
  <link rel="stylesheet" href="https://MatteoMagnini.github.io/talk-2024-aequitas/css/custom-theme.min.2abad5fe437215b2f3f11f57457d5ca4fe1939107bc4d1ecec59f2e1c3f5ad23.css" id="theme"><link rel="stylesheet" href="https://MatteoMagnini.github.io/talk-2024-aequitas/highlight-js/solarized-dark.min.css">
<link rel="stylesheet" href="https://gitcdn.link/repo/DanySK/css-blur-animation/master/blur.css">
<link href="https://fonts.googleapis.com/css?family=Roboto Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Oxygen Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu Mono" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section data-noprocess="" data-shortcode-slide="" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo.html" data-preload="true" data-transition="zoom">
<h1 id="enforcing-fairness-via-constraint-injection-with-fauci">Enforcing Fairness via Constraint Injection with FaUCI</h1>
<p><strong>2nd Aequitas Workshop on Fairness and Bias in AI</strong></p>
<p>ðŸŽ¤ <em>Matteo Magnini</em>, <strong>Giovanni Ciatto</strong>, <strong>Roberta Calegari</strong>, <strong>Andrea Omicini</strong></p>
<p>ðŸ“§ <a href="mailto:gianluca.aguzzi@unibo.it">matteo.magnini@unibo.it</a></p>










<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/aequitas-logo.svg" style="height:900px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>

</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="context">Context</h2>
<h3 class="accent" id="what-do-we-mean-by-fairness">What do we mean by fairness?</h3>
<p>Fairness has different meanings to us depending on our <em>personal background</em>.</p>
<div class="container">
<span class="fragment col">
  <figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/woman-judge-light-skin-tone-svgrepo-com.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
 <figure class="">
     <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/balance-law-svgrepo-com_v2.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
     <figcaption>  </figcaption>
   </figure>
</span>
<span class="fragment col">
  <figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/businessman-svgrepo-com.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
 <figure class="">
     <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/money-cash-svgrepo-com.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
     <figcaption>  </figcaption>
   </figure>
</span>
<span class="fragment col">
  <figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/technologist-medium-skin-tone-svgrepo-com.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
 <figure class="">
     <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/free-technology-icon.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
     <figcaption>  </figcaption>
   </figure>
</span>
</div>
<div class="container">
<span class="fragment col">
  <p>For people with predominantly scientific studies, fairness is something that should be <strong>objectively measurable</strong>.
This is usually translated into the <em>fulfillment</em> of one or multiple fairness <strong>metrics</strong>.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="context-1">Context</h2>
<h3 class="accent" id="enforcing-fairness-in-ml-models">Enforcing Fairness in ML models</h3>
<div class="container">
<span class="fragment col">
  <h4 id="pre-processing">Pre-processing</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/data-preprocessing-vert.png" style="height:405px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>Methods that operate at <strong>dataset level</strong> to remove biases for sensitive groups.</p>
</span>
<span class="fragment col">
  <h4 id="in-processing">In-processing</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/in-processing-vert.png" style="height:405px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The <strong>training of the model</strong> takes into account the fairness constraints.</p>
</span>
<span class="fragment col">
  <h4 id="post-processing">Post-processing</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/post-processing-vert.png" style="height:405px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The model is treated as a black-box and only the <strong>predictions are adjusted</strong> to ensure fairness.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="context-2">Context</h2>
<h3 class="accent" id="the-in-processing-techniques">The in-processing techniques</h3>
<div class="container">
<span class="fragment col">
  <h4 id="penalty-function">Penalty function</h4>
<p>A function, usually derived from a fairness metric, is chosen to <em>measure a violation</em> of fairness/bias.
This function takes into account the <strong>input data</strong> and the <strong>modelâ€™s predictions</strong>.</p>
</span>
<span class="fragment col">
  <h4 id="function-computation">Function computation</h4>
<p>Because fairness metrics require <strong>statistical distributions</strong> to be computed, these distributions are <em>estimated on a subset (batch) of the data</em>.
The actual computation of the fairness metric is therefore done during the loss computation.</p>
</span>
<span class="fragment col">
  <h4 id="training">Training</h4>
<p>The loss function is a <em>combination</em> of the modelâ€™s loss (e.g., binary cross entropy) and the fairness penalty.
it is common to use a hyperparameter to balance the two terms.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="open-challenges">Open challenges</h2>
<h3 class="accent" id="types-of-protected-attributes">Types of protected attributes</h3>
<div class="container">
<span class="fragment col">
  <h4 id="binary">Binary</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/binary-data.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>It is the <strong>simplest case</strong>, where the protected attribute can take only two values.
There are only two groups to be considered, the classic example is the gender.</p>
</span>
<span class="fragment col">
  <h4 id="categorical">Categorical</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/categorical-data.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The protected attribute can take more than two values.
Here things start to get tricky, as we might <strong>consider all the groups for fairness</strong>.
Examples are ethnicity, education, and occupation.</p>
</span>
<span class="fragment col">
  <h4 id="continuous">Continuous</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/continuous-data.svg" style="height:180px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The protected attribute is a continuous variable.
This is the <em>most complex case</em>, as we need to <strong>estimate probability densities</strong> to compute fairness metrics.
An example is the income.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="open-challenges-1">Open challenges</h2>
<h3 class="accent" id="fairness-metrics">Fairness metrics</h3>
<div class="container">
<span class="fragment col">
  <h4 id="group-vs-individual-fairness">Group vs. Individual fairness</h4>
<p>Group fairness is about <strong>treating groups equally</strong>, while individual fairness is about <strong>treating similar individuals equally</strong>.</p>
<p>Individual fairness metrics are more <em>computationally expensive</em> and because of that less common in practice.</p>
<p>However, also group fairness metrics can be computationally expensive.
For this reason, we decided to focus on group fairness metrics.</p>
</span>
<span class="fragment col">
  <ul>
<li><em>Demographic/statistical parity</em> how much modelâ€™s predictions are <strong>independent</strong> of the protected attribute.
<small>$$DP_{h, A}(X) = \sum_{a \in A} \left|\left| E[h(X) \mid A{=}a] - E[h(X)] \right|\right|$$</small></li>
<li><em>Disparate impact</em> how much the model <strong>disproportionately</strong> affects a group.
<small>$$DI_{h, A}(X) = \min\left(\frac{E[h(X) \mid A{=}1]}{E[h(X) \mid A{=}0]},\frac{E[h(X) \mid A{=}0]}{E[h(X) \mid A{=}1]}\right)$$</small></li>
<li><em>Equalized odds</em> how much the model <strong>equally predicts</strong> a given output for all the groups.
<small>$$EO_{h, A}(X) = \sum_{(a, y)}^{A \times Y} eo_{h, A}(X, a, y)$$</small>
<small>$$eo_{h, A}(X, a, y) = \left|\left| E[h(X) \mid A{=}a, Y{=}y] - E[h(X) \mid Y{=}y] \right|\right|$$</small></li>
</ul>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="fauci">FaUCI</h2>
<h3 class="accent" id="fairness-under-constraints-injection">Fairness under Constraints Injection</h3>
<div class="container">
<span class="fragment col">
  <p>We design FaUCI in order to be <em>agnostic</em> to the fairness metric used and to the protected attribute type:</p>
<ul>
<li>we considered <strong>demographic parity</strong>, <strong>disparate impact</strong>, and <strong>equalized odds</strong> (any other metric can be used)</li>
<li>we generalized the metric to work with <strong>binary</strong>, <strong>categorical</strong>, and <strong>continuous</strong> protected attributes</li>
<li>we also considered ad-hoc weights for the groups to cover <em>corner cases</em> (e.g., strong imbalance)</li>
</ul>
</span>
</div>
<p><br><br></p>
<div class="container">
<span class="fragment col">
  <h4 id="loss-function">Loss function</h4>
<p><small>$$L_{h,A}(X, Y) = E(h(X), Y) + \lambda F_{h,A}(X)$$</small></p>
</span>
<span class="fragment col">
  <h4 id="binary-and-categorical">Binary and categorical</h4>
<p><small>$$WDP_{h, A}(X) = \sum_{a \in A} \left|\left| E[h(X) \mid A{=}a] - E[h(X)] \right|\right| \cdot w_{a}$$</small>
<small>$$WDI_{h, A}(X) = \sum_{a \in A} \eta\left(\frac{E\left[h(X) \mid A{=}a\right]}{E\left[h(X) \mid A{\ne}a\right]}\right) \cdot w_{a}$$</small>
<small>$$WEO_{h, A}(X) = \sum_{(a, y)}^{A \times Y} eo_{h, A}(X, a, y) \cdot w_{a}$$</small></p>
</span>
<span class="fragment col">
  <h4 id="continuous">Continuous</h4>
<p><small>$$GDP_{h, A}(X) = \int_{l}^{u}(\left|\left|E[h(X) \mid A{=}a] - E[h(X)]\right|\right| \cdot w_{a}) \cdot da$$</small>
<small>$$GDI_{h, A}(X) = \int_{l}^{u} \eta\left(\frac{E\left[h(X) \mid A{=}a\right]}{E\left[h(X) \mid A{\ne}a\right]}\right) \cdot w_{a} \cdot da$$</small>
<small>$$GEO_{h, A}(X) = \int_{l}^{u} \sum_{(a, y)}^{A \times Y} (eo_{h, A}(X, a, 0) + eo_{h, A}(X, a, 1)) \cdot w_{a} \cdot da$$</small></p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="fauci-1">FaUCI</h2>
<h3 class="accent" id="results-on-the-adult-dataset">Results on the Adult dataset</h3>
<div class="container">
<span class="fragment col">
  <h4 id="gender-binary">Gender (binary)</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/demographic_parity_sex.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/equalized_odds_sex.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
</span>
<span class="fragment col">
  <h4 id="ethnicity-categorical">Ethnicity (categorical)</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/demographic_parity_ethnicity.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/equalized_odds_ethnicity.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
</span>
<span class="fragment col">
  <h4 id="age-continuous">Age (continuous)</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/demographic_parity_age.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<figure class="">
    <img src="https://MatteoMagnini.github.io/talk-2024-aequitas/equalized_odds_age.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-right.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="future-directions">Future directions</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="intersectionality">Intersectionality</h4>
<p>FaUCI can already be used to <strong>consider multiple protected attributes</strong> (subgroups) at the same time.
However, we still need to perform a wide empirical study of the method to understand its performance.
$$L_{h,\bar{A}}(X, Y) = E(h(X), Y) + \lambda_{1} F_{h,A_1}(X) + \dots + \lambda_{n} F_{h,A_n}(X)$$</p>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="language-for-fairness">Language for fairness</h4>
<p>We want to develop a <strong>language</strong> to help users to define <strong>ad-hoc fairness constraints</strong> in a more intuitive way.
Many potential users do not have a strong background in ML and statistics, so we aim to <strong>make fairness techniques more accessible</strong>.
This is something very similar to what happen with <em>symbolic knowledge injection</em> methods.</p>
</span>
<span class="fragment col">
  <h4 class="accent" id="automl-for-fairness">AutoML for fairness</h4>
<p>Because the training of ML models requires many hyperparameters â€“ and with the addition of fairness constraints there is usually one more â€“ we want to use AutoML tools to study the <strong>convergence of the best hyperparameters</strong> and how well they perform.
In this way we can fairly compare different fairness techniques and understand which one is the best.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true" data-background-iframe="https://MatteoMagnini.github.io/talk-2024-aequitas/logo-big.html" data-preload="true" data-transition="zoom">
<h2 class="highlight" id="thank-you-for-your-attention">Thank you for your attention!</h2>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-hugo/object-assign.js"></script>

<a href="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/dist/print/" id="print-location" style="display: none;"></a>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"custom-theme.scss","custom_theme_compile":true,"custom_theme_options":{"enablesourcemap":true,"targetpath":"css/custom-theme.css"},"height":900,"highlight_theme":"solarized-dark","history":true,"mermaid":[{"startOnLoad":false,"theme":"default"}],"slide_number":true,"theme":"serif","transition":"slide","transition_speed":"normal","width":1440}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/dist/reveal.js"></script>


  
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/plugin/notes/notes.js"></script>
  
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/talk-2024-aequitas/reveal-js/plugin/notes/notes.js"></script>




<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };

  var revealHugoPlugins = { 
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom ]
   };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));
  Reveal.initialize(options);
</script>






  

  

  



    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>

<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

    
  

</body></html>